# FvA training config

includes { path: "agents/cfr1p_02_fastbot.prototxt"; mount: "search_rollout.agent" }
exploit {
    model_path: "models/neurips_supervised_heavy.ckpt"
    value_model_path: "models/neurips21_supervised_heavy"
    critic_weight: 1.0
    discounting: 1.0
    search_policy_weight: 0.1   # Has no effect due to separate nets. Must present to enable policy learning.
    search_policy_update_prob: 0.4
    num_train_gpus: 4
    bootstrap_offline_targets: true
    use_distributed_data_parallel: true
    optimizer {
        adam {
            lr: 1e-4
        }
        grad_clip: 0.5
    }
    search_rollout {
        initial_games_index_file: "data/202009_2powers/game_france_austria.index"
        agent {
            cfr1p {
                model_path: "models/neurips21_supervised.ckpt"
                rollouts_cfg {
                    max_rollout_length: 0
                    n_threads: 0
                }
                n_rollouts: 256
                use_final_iter: false
                cache_rollout_results: true
                plausible_orders_cfg {
                    n_plausible_orders: 50
                    max_actions_units_ratio: 0.0
                    req_size: 250
                    batch_size: 250
                }
                half_precision: true
            }
        }
        extra_params {
            explore_eps: 0.1
            explore_s1901m_eps: 0.8
            explore_f1901m_eps: 0.5
            independent_explore: true
            discounting: 0.99
            use_trained_policy: 1
            use_ev_targets: 1
        }
        chunk_length: 128
        batch_size: 8
        warmup_batches: 50
        num_workers_per_gpu: 8
        num_cores_to_reserve: 70
        draw_on_stalemate_years: 3
        enforce_train_gen_ratio: 6
        buffer {
            capacity: 10000
            # Right after warmup.
            save_at: 100
            prefetch: 5
            shuffle: true
        }
        test_situation_eval {
            do_eval: false
        }
    }
    trainer {
        max_epochs: 3001
        epoch_size: 100
        save_checkpoint_every: 10
        save_sync_checkpoint_every: 20
    }
}
